{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams detection\n",
    "\n",
    "NLTK (PMI) : \n",
    "$\\log\\frac{\\mathrm{count}(a, b)}{\\mathrm{count}(a)\\mathrm{count}(b)} > \\mathrm{threshold}$\n",
    "\n",
    "Gensim :\n",
    "$\\frac{\\mathrm{count}(a, b)-\\delta}{\\mathrm{count}(a)\\mathrm{count}(b)}> \\mathrm{threshold}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS-tagging and lemmatization with TreeTagger\n",
    "https://github.com/miotto/treetagger-python\n",
    "\n",
    "http://treetaggerwrapper.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['je', 'aimer', 'le', 'huitres']\n",
      "['je_PRO:PER', 'aimer_VER:pres', 'le_DET:ART', 'huitres_NOM']\n"
     ]
    }
   ],
   "source": [
    "import treetaggerwrapper\n",
    "\n",
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "\n",
    "def lemmatize(text):\n",
    "    tags = tagger.tag_text(text)\n",
    "    return [tag.split('\\t')[2] for tag in tags]\n",
    "\n",
    "def pos_tag(text):\n",
    "    tags = tagger.tag_text(text)\n",
    "    return [tag.split('\\t')[2] + \"_\" + tag.split('\\t')[1] for tag in tags]\n",
    "\n",
    "print(lemmatize(\"J'aime les huitres\"))\n",
    "print(pos_tag(\"J'aime les huitres\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER\n",
    "\n",
    "With [Polyglot](http://polyglot.readthedocs.io/en/latest/Installation.html) (follow [this link](https://github.com/aboSamoor/polyglot/issues/80) for installation on MAC-OS)\n",
    "\n",
    "[Paper](https://de4e3a17-a-62cb3a1a-s-sites.googlegroups.com/site/rmyeid/papers/polyglot-ner.pdf?attachauth=ANoY7crynou5qQf-wEyzXxfep8bEI4awmcUu63xbhxdHjVo70BdH5Z972VHKvKMmzCkI3ypSo8niY0DXbD5h1iluz3OihfRqOaSKZ0fzBq4nY4IrT6rsav-1pnQrkhk7q5fiQvMuowAjSlWZMvwZYk42urhm5Ac0q3NMpwOwFb4u0eUJ5YWEteHYGvrN_bswK27TzXNHXTAxPGhO5GcqXibFzxdL8clSRw%3D%3D&attredirects=0) for the NER part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: polyglot: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "polyglot download embeddings2.fr ner2.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I-PER(['Bernard', 'Duchemin']), I-LOC(['Paris'])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text, Word\n",
    "\n",
    "blob = \"\"\"Je m'appelle Bernard Duchemin je vais à Paris. \"\"\"\n",
    "text = Text(blob, hint_language_code='fr')\n",
    "text.entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Orthographic correction\n",
    "FR:\n",
    "http://blog.proxteam.eu/2013/10/un-correcteur-orthographique-en-21.html\n",
    "\n",
    "http://pythonhosted.org/pyenchant/tutorial.html\n",
    "\n",
    "EN:\n",
    "https://pypi.python.org/pypi/autocorrect/0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Corpora\n",
    "Annotated Wikipedia: https://github.com/AKSW/FOX/blob/master/input/Wikiner/aij-wikiner-fr-wp2.bz2\n",
    "\n",
    "Raw Wikipedia (FR): http://embeddings.org/frWiki_non_lem.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings \n",
    "http://fauconnier.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sentiment Analysis in French\n",
    "https://github.com/sloria/textblob-fr\n",
    "\n",
    "or Polyglot (see above)\n",
    "\n",
    "Tweeter corpus: https://deft.limsi.fr/2015/corpus.fr.php?lang=fr\n",
    "\n",
    "Tweeter aussi : https://github.com/ressources-tal/canephore\n",
    "\n",
    "Various product ressources : http://alt.qcri.org/semeval2016/task5/index.php?id=data-and-tools\n",
    "\n",
    "Scrap French IMDB: http://deeper.solutions/blog/2016/12/13/scrapping-movie-data-from-static-web/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Quelle', 'DT'), ('belle', 'JJ'), ('matinée', 'NN')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "text = u\"Quelle belle matinée\"\n",
    "blob = TextBlob(text, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Chunking and dependency parser\n",
    "\n",
    "Meaning of POS-tags: http://universaldependencies.org/fr/pos/index.html\n",
    "\n",
    "Meaning of dependency relations http://universaldependencies.org/fr/dep/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk import Tree\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'aime les huitres ?\n",
      "        aime_VERB             \n",
      "    ________|__________        \n",
      "   |        |     huitres_NOUN\n",
      "   |        |          |       \n",
      "J'_PRON  ?_PUNCT    les_DET   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"J'aime les huitres ?\")\n",
    "print(doc)\n",
    "\n",
    "\n",
    "def tok_format(tok):\n",
    "    return \"_\".join([tok.orth_, tok.tag_])\n",
    "\n",
    "\n",
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(tok_format(node), [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return tok_format(node)\n",
    "    \n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salut INTJ nsubj va\n",
      "ça PRON nsubj va\n",
      "ne ADV advmod va\n",
      "va VERB ROOT va\n",
      "pas ADV advmod va\n",
      "à ADP case Paris\n",
      "Paris PROPN obl va\n",
      ", PUNCT punct es\n",
      "tu PRON nsubj es\n",
      "es AUX ccomp va\n",
      "sûr ADJ amod va\n",
      "? PUNCT punct sûr\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word.text, word.pos_, word.dep_, word.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
